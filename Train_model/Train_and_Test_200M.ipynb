{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osï¼Œ gc, math, CustomAttention\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse examples\n",
    "def decode(example):\n",
    "    features = {\n",
    "        'ecg': tf.io.FixedLenFeature([4098], tf.float32),\n",
    "        'label': tf.io.FixedLenFeature([1], tf.int64),\n",
    "    }\n",
    "    feature_dict = tf.io.parse_single_example(example,features)\n",
    "    ecg = feature_dict['ecg']\n",
    "    label = feature_dict['label']\n",
    "    return ecg,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "sample_size = 15048*67\n",
    "val_size = 152*67\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCH_NUM = 50\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 48000\n",
    "NUM_PARALEEL_CALLS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [i for i in os.walk('/tmpdata/train1/')][0][2] # get all file path\n",
    "filenames = ['/tmpdata/train1/'+file for file in temp]\n",
    "print(filenames)\n",
    "\n",
    "dataset_train = tf.data.TFRecordDataset(filenames) # load train dataset\n",
    "\n",
    "dataset_train = dataset_train.shuffle(buffer_size = BUFFER_SIZE).repeat() # dataset preprocessing\n",
    "dataset_train = dataset_train.map(decode,num_parallel_calls = NUM_PARALEEL_CALLS)\n",
    "dataset_train = dataset_train.batch(batch_size = BATCH_SIZE)\n",
    "dataset_train = dataset_train.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = [i for i in os.walk('/tmpdata/val1/')][0][2] # get all file path\n",
    "filenames = ['/tmpdata/val1/'+file for file in temp]\n",
    "print(filenames)\n",
    "\n",
    "dataset_val = tf.data.TFRecordDataset(filenames) # load val dataset\n",
    "\n",
    "dataset_val = dataset_val.map(decode,num_parallel_calls = NUM_PARALEEL_CALLS) # dataset preprocessing\n",
    "dataset_val = dataset_val.batch(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred): # custom f1 score metric\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_dense_drop.h5', custom_objects={'CustomAttention': CustomAttention.CustomAttention})\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_f1', factor=0.7,patience=5, min_lr=0.0005)\n",
    "\n",
    "model_check = ModelCheckpoint(filepath = \"../../model/model_{epoch:03d}.h5\",\n",
    "                             monitor = 'val_loss', mode = 'min'),\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate = LEARNING_RATE),\n",
    "    metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),f1],\n",
    ")\n",
    "\n",
    "history = model.fit(dataset_train,epochs=EPOCH_NUM, steps_per_epoch = sample_size/BATCH_SIZE, \n",
    "                    validation_data=dataset_val,verbose = 1,callbacks=[reduce_lr,model_check])\n",
    "\n",
    "# store model\n",
    "model.save(\"model_attention_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_metric(rate,size,history):\n",
    "    metrics = [key for key in history.history.keys()][:5]   # plot all metric information\n",
    "\n",
    "    for metric in metrics:\n",
    "        fig = plt.figure(figsize=(10,3))\n",
    "        plt.plot(history.history[metric])\n",
    "        plt.plot(history.history['val_'+metric])\n",
    "        plt.title(metric+ ' rate: '+str(rate)+' size: '+str(size))\n",
    "        plt.ylabel(metric)\n",
    "        plt.xlabel('epoch')\n",
    "\n",
    "        plt.legend(['train', 'val'], loc='upper left')\n",
    "        plt.show()\n",
    "        \n",
    "plot_metric(0.01,256,history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(model):\n",
    "    figure = plt.figure(figsize = (10,5))      # plot attention weight\n",
    "    weights= model.get_weights()[0][0][:].reshape((1,512,1))\n",
    "    sig = 1/(1 + np.exp(-pool))\n",
    "    result = sig[0].reshape((512))\n",
    "\n",
    "    plt.plot(2*result)\n",
    "    plt.axvline(256)\n",
    "    plt.axvline(236, color = 'red')\n",
    "    plt.axvline(276, color = 'red')\n",
    "    \n",
    "plot_attention(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_misclassify(model_path, dataset_val):\n",
    "    model = load_model(model_path, custom_objects={'CustomAttention': CustomAttention.CustomAttention,'f1':f1})\n",
    "    x = list(dataset_val.as_numpy_iterator())[0][0] # get predicted probability of each sample in val\n",
    "    test_prob = model.predict(x) \n",
    "    y_hat = np.empty((test_prob.shape[0],1)) # turn the probability to 0 or 1\n",
    "    for i,prob in enumerate(test_prob):\n",
    "        y_hat[i] = prob>0.5\n",
    "        \n",
    "    y_true = list(dataset_val.as_numpy_iterator())[0][1]\n",
    "\n",
    "    misclass = np.array([],dtype = int) # count total number of misclassified sample\n",
    "    for i,pred in enumerate(y_true):\n",
    "        if not np.array_equal(pred,y_hat[i]):\n",
    "            misclass = np.append(misclass,i)\n",
    "    return misclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_misclassify(misclass, num_to_plot = 10): # plot designated number of misclassified samples and their position in record\n",
    "    for i in misclass[:num_to_plot]: \n",
    "        fig = plt.figure(figsize = (8,2))\n",
    "        plt.plot(x[i][:4096].reshape(512,8).T[0])\n",
    "        plt.axvline(236)\n",
    "        plt.axvline(276)\n",
    "        plt.title(str(y_true[i]) + ' ' + str(x[i][-2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
