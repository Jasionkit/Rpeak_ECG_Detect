{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:\n",
    "\n",
    "1. Segment record to 512 points width periods. For each period, do stationary wavelet transform and use YOLO model to predict. \n",
    "\n",
    "\n",
    "2. Do nonmax suppression:\n",
    "\n",
    "    1) for each grid, discard predicted box with p<=0.5\n",
    "    \n",
    "    2) for every two adjacent period, calculate the IOU. If IOU>=0.5, discard the box with lower possibility.\n",
    "    \n",
    "\n",
    "3. Calculate the general position using the predicted relative position\n",
    "\n",
    "\n",
    "4. Draw the graph after each step/ Calculate recall and sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, h5py, os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from Stationary_transform import *\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def f1_value(y_true, y_pred): # custom f1 score metric\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "def yolo_loss(y_true, y_pred):\n",
    "    true_x = y_true[...,1]\n",
    "    pred_x = y_pred[...,1]\n",
    "    pred_prob = y_pred[...,0]\n",
    "    object_mask = y_true[...,0]\n",
    "    \n",
    "    object_loss = 3*object_mask*K.square(1-pred_prob)\n",
    "    no_object_loss = 2*(1-object_mask)*K.square(0-pred_prob)\n",
    "    x_loss = 5*object_mask*K.square(true_x-pred_x)\n",
    "    loss = object_loss + no_object_loss + x_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ecg, yolo_model):\n",
    "    \n",
    "    size = len(ecg)//512\n",
    "\n",
    "    data_x = np.empty((size,4098,1),'float32')\n",
    "\n",
    "    for i in range(size):\n",
    "        sample = decomp(ecg[i*512:(i+1)*512],'db2',(512,8))\n",
    "        data_x[i][:4096] = sample.reshape(4096,1)\n",
    "\n",
    "    data_y = yolo_model.predict(data_x) # ? * 8 * 2\n",
    "    return data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonmax Suppression and Locate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''discard predicted box with p<=0.5'''\n",
    "\n",
    "\n",
    "def binarize(data_y):\n",
    "    data_y = np.reshape(data_y,(-1,2)) # (?*8) * 2\n",
    "\n",
    "    mask = data_y[:,0]>0.5\n",
    "    mask = np.expand_dims(mask.astype('int'),0)\n",
    "    mask = np.transpose(np.insert(mask,1,mask[0],axis = 0))\n",
    "\n",
    "    data_y = data_y*mask # (?*8) * 2\n",
    "    return data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(gridl, gridr):\n",
    "    \n",
    "    gridl_x, gridr_x = gridl[1],gridr[1]\n",
    "    gridl_l, gridl_r = gridl_x-25, gridl_x+25\n",
    "    gridr_l, gridr_r = gridr_x-25, gridr_x+25\n",
    "    \n",
    "    intersect = max(gridl_r-gridr_l,0)\n",
    "    union = 50+50-intersect    \n",
    "    iou = intersect/union\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''For every two adjacent periods, calculate the IOU. If IOU>=0.5, discard the box with lower possibility.\n",
    "   Store all predicted R peak in R array\n",
    "'''\n",
    "\n",
    "def nonmax_suppress(data_y, ecg):\n",
    "    R = np.zeros((len(ecg)),'int')\n",
    "\n",
    "    for i in range(data_y.shape[0]):\n",
    "        if i<len(data_y)-1:\n",
    "            if data_y[i,0] != 0 and data_y[i+1,0] != 0: # when 2 adjacent periods both predict R\n",
    "                iou_score = iou(data_y[i],data_y[i+1])\n",
    "                if iou_score>=0.5:\n",
    "                    min_index = np.argmin([data_y[i,0],data_y[i+1,0]])+i\n",
    "                    max_index = np.argmax([data_y[i,0],data_y[i+1,0]])+i\n",
    "                    data_y[min_index] = [0,0]\n",
    "                    R[int((max_index+data_y[max_index,1])*64)] = 1\n",
    "                else:\n",
    "                    R[int((i+data_y[i,1])*64)] = 1\n",
    "            if data_y[i,0] != 0 and data_y[i+1,0] == 0: # when only the former period predict R\n",
    "                R[int((i+data_y[i,1])*64)] = 1\n",
    "        if i == len(data_y)-1 and data_y[i,0] != 0:\n",
    "            R[int((i+data_y[i,1])*64)] = 1\n",
    "            \n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Process annotation and create annot storaging all true R position in record'''\n",
    "\n",
    "def ann_process(ecg,path):\n",
    "    annot = np.zeros((len(ecg)),'int')\n",
    "\n",
    "    with open(path+'/ann.txt','r') as f:\n",
    "        for line in f:\n",
    "            pos, ann = line.rstrip().split(',')[:2]\n",
    "            pos = round(int(pos)/1000*256)\n",
    "            if ann =='X':\n",
    "                continue\n",
    "            elif pos>len(ecg):\n",
    "                break\n",
    "            else:\n",
    "                annot[pos] = 1\n",
    "    f.close()\n",
    "    return annot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall and Precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Calculate recall and precision based on true R position and predicted R position'''\n",
    "\n",
    "def correspond(ary, index):\n",
    "    for i in range(11):\n",
    "        if ary[index+i]==1:\n",
    "            return index+i+1\n",
    "    return -1\n",
    "\n",
    "def measure(Rs, annot, record):\n",
    "    \n",
    "    nn,no,on, i = 0,0,0,0 #TP, FN, FP\n",
    "\n",
    "    f_no = open('../../record/yolo_no_'+record+'2.txt','w')\n",
    "    f_on = open('../../record/yolo_on_'+record+'2.txt','w')\n",
    "    \n",
    "    while i<len(annot):\n",
    "        if Rs[i] == 1:\n",
    "            index = correspond(annot, i)\n",
    "            if index == -1:\n",
    "                f_on.write(str(i)+'\\n')\n",
    "                on += 1\n",
    "            else:\n",
    "                nn += 1\n",
    "                i = index\n",
    "                continue\n",
    "        elif annot[i] == 1:\n",
    "            index = correspond(Rs, i)\n",
    "            if index == -1:\n",
    "                f_no.write(str(i)+'\\n')\n",
    "                no += 1\n",
    "            else:\n",
    "                nn += 1\n",
    "                i = index\n",
    "                continue\n",
    "        i+=1\n",
    "    f_on.close()\n",
    "    f_no.close()\n",
    "    se = nn/(nn+no+K.epsilon())\n",
    "    prec = nn/(nn+on+K.epsilon())\n",
    "    return se, prec \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model_path = '../../model/new_yolo_model/model_035.h5', database_path = '../../record/'):\n",
    "    \n",
    "    files = sorted([i for i in os.walk(database_path)][0][1])\n",
    "    files.remove('.ipynb_checkpoints')\n",
    "\n",
    "    sensitivity, precision = 0,0\n",
    "\n",
    "    for record in files:\n",
    "\n",
    "        yolo_model = load_model(model_path,custom_objects={'yolo_loss': yolo_loss, 'f1_value': f1_value})\n",
    "\n",
    "        path = database_path+record\n",
    "        ecg = np.fromfile(path+'/ecg.dat', '>i2') # plot original ecg sequence\n",
    "        ecg = ecg[:len(ecg)-(len(ecg))%512]\n",
    "\n",
    "        data_y = predict(ecg, yolo_model)\n",
    "        data_y = binarize(data_y)\n",
    "        R = nonmax_suppress(data_y, ecg)\n",
    "        annot = ann_process(ecg,path)\n",
    "\n",
    "        se,prec = measure(R,annot,record)\n",
    "        sensitivity += se\n",
    "        precision += prec\n",
    "        f1 = (2*se*prec)/(se+prec)\n",
    "        print(record + ': sensitivity: '+str(se)+ '   precision: '+ str(prec)+ '   f1: '+ str(f1))\n",
    "\n",
    "        del yolo_model\n",
    "        gc.collect()\n",
    "\n",
    "    print('Average sensitivity: ', str(sensitivity/67))\n",
    "    print('Average precision: ', str(precision/67))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000: sensitivity: 0.9994905805449832   precision: 0.9998749999990386   f1: 0.9996827533157088\n",
      "20001: sensitivity: 0.9953870642876529   precision: 0.9996411327145596   f1: 0.9975095629516318\n",
      "20002: sensitivity: 0.9963535218186629   precision: 0.9999234049063412   f1: 0.9981352714042399\n",
      "20003: sensitivity: 0.9690740666471757   precision: 0.9959610613333476   f1: 0.9823336205907364\n",
      "20004: sensitivity: 0.988600924829741   precision: 0.9994111305378648   f1: 0.9939766363762561\n",
      "20005: sensitivity: 0.9931582304159243   precision: 0.9985232108495438   f1: 0.9958334948248171\n",
      "20006: sensitivity: 0.9981317319597768   precision: 0.9998854152731892   f1: 0.999007804002176\n",
      "20007: sensitivity: 0.9900753014359707   precision: 0.9996579415849746   f1: 0.9948435463086717\n",
      "20008: sensitivity: 0.9972780868147705   precision: 0.9993806205693534   f1: 0.9983282466805901\n",
      "20009: sensitivity: 0.9863467821511853   precision: 0.9991750055798748   f1: 0.9927194530419255\n",
      "20010: sensitivity: 0.762608128667018   precision: 0.9981452402073255   f1: 0.8646227089249118\n",
      "20011: sensitivity: 0.994691617337221   precision: 0.9998752363302208   f1: 0.9972766910590299\n",
      "20012: sensitivity: 0.9986870266078242   precision: 0.9999240115798753   f1: 0.999305136295048\n",
      "20013: sensitivity: 0.9990009131428275   precision: 0.9998064724212452   f1: 0.999403530453801\n",
      "20014: sensitivity: 0.9970453934990781   precision: 0.999889084310976   f1: 0.9984652141572139\n",
      "20015: sensitivity: 0.993007864420424   precision: 0.997982299898422   f1: 0.9954888679126707\n",
      "20016: sensitivity: 0.9917832272133789   precision: 0.9993987648904469   f1: 0.9955764327386796\n",
      "20017: sensitivity: 0.616101313078804   precision: 0.9602357514565675   f1: 0.750604068948895\n",
      "20018: sensitivity: 0.9882327388932505   precision: 0.9999293613473146   f1: 0.9940466437263531\n",
      "20019: sensitivity: 0.998633621150064   precision: 0.9997445490045653   f1: 0.9991887762867374\n",
      "20020: sensitivity: 0.7419598392343509   precision: 0.9817550657937941   f1: 0.8451778523919875\n",
      "20021: sensitivity: 0.9804223448807118   precision: 0.9989040270150499   f1: 0.9895769008916706\n",
      "20022: sensitivity: 0.9962895625384992   precision: 0.9998324365576885   f1: 0.9980578554626318\n",
      "20023: sensitivity: 0.9977087843934609   precision: 0.999663016005687   f1: 0.9986849441879807\n",
      "20024: sensitivity: 0.9994639438408853   precision: 0.9999659475924949   f1: 0.9997148826967844\n",
      "20025: sensitivity: 0.984954441678166   precision: 0.9983946460392599   f1: 0.9916290049532358\n",
      "20026: sensitivity: 0.9370209441968649   precision: 0.9990977078299881   f1: 0.9670641585480626\n",
      "20027: sensitivity: 0.9980175302643648   precision: 0.9997681381483313   f1: 0.9988920672001541\n",
      "20028: sensitivity: 0.9804064733361562   precision: 0.9992120814173787   f1: 0.9897199543871299\n",
      "20029: sensitivity: 0.8653965604246424   precision: 0.939420757081514   f1: 0.9008906154482116\n",
      "20030: sensitivity: 0.9927430925153953   precision: 0.9995433364389567   f1: 0.9961316088875509\n",
      "20031: sensitivity: 0.7483903329517154   precision: 0.9842112662337552   f1: 0.850252242151672\n",
      "20032: sensitivity: 0.9874555646696511   precision: 0.9994032432423788   f1: 0.9933934811660541\n",
      "20033: sensitivity: 0.9431903763551638   precision: 0.9959806555604557   f1: 0.9688669579934254\n",
      "20034: sensitivity: 0.9978294981527265   precision: 0.9997740538495578   f1: 0.9988008295428586\n",
      "20035: sensitivity: 0.9920144844663693   precision: 0.9997887134560718   f1: 0.9958864271218422\n",
      "20036: sensitivity: 0.9894458059917863   precision: 0.9997443824031251   f1: 0.9945684349376427\n",
      "20037: sensitivity: 0.9972433594016441   precision: 0.9998057446593028   f1: 0.9985229081504619\n",
      "20038: sensitivity: 0.9978401967071331   precision: 0.9998668190837154   f1: 0.9988524799172911\n",
      "20039: sensitivity: 0.9937180120848597   precision: 0.999663170050204   f1: 0.9966817255019416\n",
      "20040: sensitivity: 0.9683634136669417   precision: 0.9973286634405351   f1: 0.982632631351202\n",
      "20041: sensitivity: 0.9923642456250127   precision: 0.9996956337265502   f1: 0.9960164488033302\n",
      "20042: sensitivity: 0.9846590294581703   precision: 0.9975557746921561   f1: 0.9910654474804135\n",
      "20043: sensitivity: 0.9968554002444867   precision: 0.9997747279398006   f1: 0.9983129298775807\n",
      "20044: sensitivity: 0.9945414931202838   precision: 0.9980453207443248   f1: 0.9962903263116925\n",
      "20045: sensitivity: 0.9944706123275168   precision: 0.9998039138779954   f1: 0.9971301316609574\n",
      "20046: sensitivity: 0.9821548886355496   precision: 0.9998334264175903   f1: 0.990915314806929\n",
      "20047: sensitivity: 0.993075112841911   precision: 0.9982452228363421   f1: 0.995653456202411\n",
      "20048: sensitivity: 0.901414843196881   precision: 0.9952682452022364   f1: 0.9460194743920471\n",
      "20049: sensitivity: 0.9600160705758121   precision: 0.998372256991027   f1: 0.9788185495562487\n",
      "20050: sensitivity: 0.9803540729957515   precision: 0.9987874603179558   f1: 0.9894849239410977\n",
      "20051: sensitivity: 0.9978471935095038   precision: 0.9998857110196007   f1: 0.9988654121971765\n",
      "20052: sensitivity: 0.9867142573856936   precision: 0.9994054983361992   f1: 0.9930193295515105\n",
      "20053: sensitivity: 0.9930027098249814   precision: 0.999542274242184   f1: 0.9962617605562237\n",
      "20054: sensitivity: 0.946733897462824   precision: 0.989210699621689   f1: 0.9675063041319927\n",
      "20055: sensitivity: 0.9609648944384648   precision: 0.9987232387450546   f1: 0.9794803116297753\n",
      "20056: sensitivity: 0.9909011469131721   precision: 0.9988109000814767   f1: 0.9948403015753312\n",
      "20057: sensitivity: 0.9947030078447774   precision: 0.9997750421783418   f1: 0.9972325758224395\n",
      "20058: sensitivity: 0.910399379215121   precision: 0.9906302772770733   f1: 0.9488217991600322\n",
      "20059: sensitivity: 0.9695172255339242   precision: 0.9780662017224899   f1: 0.9737729506338085\n",
      "20060: sensitivity: 0.9980163103363812   precision: 0.9999235584387236   f1: 0.998969024051015\n",
      "20061: sensitivity: 0.9685419537091219   precision: 0.9993429462279149   f1: 0.9837014040770201\n",
      "20062: sensitivity: 0.9869290141618544   precision: 0.9960134397845788   f1: 0.9914504177992713\n",
      "20063: sensitivity: 0.982419197303755   precision: 0.9983972753672167   f1: 0.9903437934701007\n",
      "20064: sensitivity: 0.9788422316670998   precision: 0.9995036834463837   f1: 0.9890650655075388\n",
      "20065: sensitivity: 0.9701827266094134   precision: 0.9996002612916439   f1: 0.9846718272785918\n",
      "20066: sensitivity: 0.91594322722748   precision: 0.9901027788335345   f1: 0.9515803203573391\n",
      "Average sensitivity:  0.9653004005795844\n",
      "Average precision:  0.9964149900903637\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
