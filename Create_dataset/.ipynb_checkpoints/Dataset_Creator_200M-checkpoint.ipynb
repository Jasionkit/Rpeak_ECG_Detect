{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary:\n",
    "1. deal with the annotation\n",
    "\n",
    "    1) create a empty set\n",
    "    \n",
    "    2) read through ann.txt. For each N, put the point and its +-20 points into the set. For X, skip.\n",
    "   \n",
    "    \n",
    "2. segment and wavelet transform\n",
    "\n",
    "    1) randomly pick a midpoint and scan through +-1.5s and see if there is a R wave. If no, throw out the midpoint. \n",
    "    \n",
    "    2) keep track of R and non-R selected. Each should be 7500.(total samples per records = 15000)\n",
    "    \n",
    "    \n",
    "3. store in TFrecords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from Stationary_transform import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annProcess(path,width=21):\n",
    "    \n",
    "    with open(path+'/ann.txt','r') as f: # read annotation\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    R = set()  # set initialize\n",
    "    R_set = set()\n",
    "    \n",
    "    ecg = np.fromfile(path+'/ecg.dat', '>i2') # get ecg length\n",
    "    ecg_len = len(ecg)\n",
    "    \n",
    "    \n",
    "    for line in lines:   # add each R wave and its surrounding to set\n",
    "        temp = line.split(',')\n",
    "        pos,typ = temp[0],temp[1]\n",
    "        if typ == 'X':\n",
    "            continue\n",
    "        pos = round(int(pos)/1000*256)\n",
    "        R_set.add(pos)\n",
    "        R.add(pos)\n",
    "        for i in range(width):\n",
    "            if pos-i>=0:\n",
    "                R_set.add(pos-i)\n",
    "            if pos+i<ecg_len:\n",
    "                R_set.add(pos+i)\n",
    "    \n",
    "    return R_set,R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Non-noise Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Check if at least 1 R wave present in the period'''\n",
    "def validPeriod(n, R_set):\n",
    "    for i in range(384):\n",
    "        if n-i in R_set or n+i in R_set:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "'''sampling noR and R period without noise'''\n",
    "def sampling_normal(path,size_R,size_nR,R_set,record):\n",
    "    ecg = np.fromfile(path +'/ecg.dat', '>i2') \n",
    "    \n",
    "    selected = set() # initialize storage for selected sequence\n",
    "\n",
    "    data_x,data_y = np.empty((size_R+size_nR,514),'float32'),np.empty((size_R+size_nR),'int')\n",
    "    \n",
    "    np.random.seed(40)\n",
    "    count_R,count_nR,count_total=0,0,0\n",
    "    \n",
    "    while count_R<size_R or count_nR<size_nR:\n",
    "        \n",
    "        if count_total%50==0:\n",
    "            print(record + ' sampling '+str(count_total)+'/ '+str(size_R+size_nR), end = '\\r')\n",
    "        \n",
    "        n = np.random.randint(256,len(ecg)-256) \n",
    "        \n",
    "        # check if has selected the period and if +-1.5s of this point has a R and if n is within QRS period\n",
    "        if n not in selected and validPeriod(n,R_set):\n",
    "            if n in R_set and count_R<size_R: \n",
    "                x = np.empty((514),'float32')\n",
    "                x[:512] = np.array([ecg[n-256:n+256]])\n",
    "                x[-2:] = [record,n]\n",
    "                data_x[count_total] = x\n",
    "                data_y[count_total] = 1\n",
    "                count_R +=1\n",
    "                count_total+=1\n",
    "            if n not in R_set and count_nR<size_nR:\n",
    "                x = np.empty((514),'float32')\n",
    "                x[:512] = np.array([ecg[n-256:n+256]])\n",
    "                x[-2:] = [record,n]\n",
    "                data_x[count_total] = x\n",
    "                data_y[count_total] = 0\n",
    "                count_nR +=1\n",
    "                count_total+=1\n",
    "            \n",
    "            selected.add(n)\n",
    "            \n",
    "    return data_x,data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling True Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''sampling true noise from each record'''\n",
    "def sampling_noise(path,R,record): \n",
    "    \n",
    "    ecg = np.fromfile(path +'/ecg.dat', '>i2') \n",
    "\n",
    "    data_x,data_y = np.empty((150000,514),'float32'),np.empty((150000),'int') \n",
    "    # 150000 is an abitrary large number. It is used cuz exact number of noise in the record is unknown\n",
    "    \n",
    "    R = sorted(list(R))\n",
    "    np.random.seed(40) \n",
    "    count_total = 0\n",
    "    \n",
    "    for i, loc in enumerate(R[1:]):\n",
    "        dis=loc-R[i]\n",
    "        if dis>1064 and count_total<150000: #1064 considered +-20 of the R peak\n",
    "            for n in range(R[i]+1,loc,25):\n",
    "                x = np.empty((514),'float32')\n",
    "                x[:512] = np.array([ecg[n-256:n+256]])\n",
    "                x[-2:] = [record,n]\n",
    "                data_x[count_total] = x\n",
    "                data_y[count_total] = 0\n",
    "                count_total+=1\n",
    "    print('     count_total '+str(count_total))\n",
    "    \n",
    "    if count_total ==0: # when no noise in the record\n",
    "        return [],[],0\n",
    "    \n",
    "    x_noise,y_noise = np.copy(data_x[:count_total]),np.copy(data_y[:count_total]) # make copy to avoid memory leak\n",
    "    del data_x\n",
    "    del data_y\n",
    "    \n",
    "    return x_noise,y_noise,count_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Regular Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create sine/square/triangle waves as regular noise'''\n",
    "\n",
    "def get_sin(freq_low, freq_high, size=747):\n",
    "    \n",
    "    data_x, data_y = np.empty((size,514),'float32'),np.empty((size),'int')\n",
    "    \n",
    "    count = 0\n",
    "    time = np.arange(512)\n",
    "    for freq in range(freq_low, freq_high+1):  # get sine with multiple frequency and phase\n",
    "        B = 2*np.pi*freq/256\n",
    "        for phi in range(int(256/freq)):\n",
    "            print('Get sine '+str(count)+'/ '+str(size), end = '\\r')\n",
    "            sine = np.sin(B*time-B*phi)\n",
    "            data_x[count] = append(sine,[0,0])\n",
    "            data_y[count] = 0\n",
    "            count+=1 \n",
    "    return data_x,data_y\n",
    "    \n",
    "def get_square(freq_low, freq_high, size=747):\n",
    "    data_x, data_y = np.empty((size,514),'float32'),np.empty((size),'int')\n",
    "    count = 0\n",
    "    \n",
    "    for freq in range(freq_low, freq_high+1):\n",
    "        square = np.zeros(1024,'float32')  # generate square wave wiht length 1024, but will only crop 512 segment from it\n",
    "        length,pos,i = int(256/(2*freq)),1,0\n",
    "        while i< 4*2*freq:\n",
    "            square[i*length:(i+1)*length] = np.ones(length,'int')*pos\n",
    "            pos *= -1\n",
    "            i+=1 \n",
    "        for phi in range(int(256/freq)): # sliding window to crop the length 512 from square wave according to phi\n",
    "            print('Get square '+str(count)+'/ '+str(size), end = '\\r')\n",
    "            data_x[count]=np.append(square[phi:phi+512],[0,0])\n",
    "            data_y[count] = 0\n",
    "            count+=1\n",
    "    return data_x, data_y\n",
    "    \n",
    "def get_triangle(freq_low, freq_high,size=747):\n",
    "    data_x, data_y = np.empty((size,514),'float32'),np.empty((size),'int')\n",
    "    count = 0\n",
    "    \n",
    "    for freq in range(freq_low, freq_high+1):\n",
    "        tran = np.zeros(1024,'float32')   # generate square wave wiht length 1024, but will only crop 512 segment from it\n",
    "        slope, part, period = 1/(256/(4*freq)), 256/(4*freq), 256//freq\n",
    "        for i in range(256//freq):  # draw triangle wave with length 256\n",
    "            m = 256/(4*freq)\n",
    "            if (i//(256/(4*freq)))%4==0:\n",
    "                tran[i] = slope*i\n",
    "            elif (i//(256/(4*freq)))%4==3:\n",
    "                tran[i] = slope*i+(-1-slope*(3*part))\n",
    "            else:\n",
    "                tran[i] = -slope*i+slope*(part*2)\n",
    "        for i in range(1,4*freq): # copy length 256 for multi-times to make full 1024 length wave\n",
    "            tran[i*period:(i+1)*period] = tran[:period]\n",
    "\n",
    "        for phi in range(int(256/freq)): # sliding window to crop the length 512 from square wave according to phase\n",
    "            print('Get triangle '+str(count)+'/ '+str(size), end = '\\r')\n",
    "            data_x[count]=np.append(tran[phi:phi+512],[0,0])\n",
    "            data_y[count] = 0\n",
    "            count+=1\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFRecord Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def putSample(writer, size, data_x, data_y):\n",
    "    for i in range(size):\n",
    "        \n",
    "        if i%500 ==0:\n",
    "            print('      store '+str(i)+'/ '+str(size), end = '\\r')\n",
    "            \n",
    "        y = data_y[i]\n",
    "        \n",
    "        sample = decomp(data_x[i][:-2],'db2',(512,8)).reshape(4096) # decompose each sample\n",
    "        x = np.empty((4098),'float32')\n",
    "        x[:4096] = sample\n",
    "        x[-2:] = data_x[i][-2:]\n",
    "\n",
    "        # create example\n",
    "        feature = {\n",
    "            'ecg': tf.train.Feature(float_list=tf.train.FloatList(value=x)),\n",
    "            'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[y])),\n",
    "        }\n",
    "        example = tf.train.Example(features = tf.train.Features(feature = feature))\n",
    "        writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSubdir(path):\n",
    "    subdir = [x for x in os.walk(path)]\n",
    "    return subdir[0][1]\n",
    "\n",
    "def shuffle_and_split(data_x,data_y,seed = 10,size = 0.03):\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(data_x)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(data_y)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(data_x,data_y, test_size=0.03)\n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20001 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 125\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20002 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20003 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 902\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20004 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 1567\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20005 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20006 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 43\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20007 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 95\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20008 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 102\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20009 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 271\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20010 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 7533\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20011 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20012 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20013 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20014 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20015 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 68471\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20016 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 285\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20017 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 2853\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20018 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20019 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20020 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 33608\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20021 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 604\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20022 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 290\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20023 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 49\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20024 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20025 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 258\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20026 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20027 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 68\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20028 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 294\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20029 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 1154\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20030 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20031 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 1577\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20032 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 33651\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20033 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 48\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20034 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 192\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20035 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 182\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20036 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 3541\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20037 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 9766\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20038 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 122\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20039 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 291\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20040 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 159\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20041 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20042 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 22038\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20043 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20044 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 98\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20045 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20046 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20047 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20048 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 57\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20049 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 5371\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20050 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 176\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20051 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20052 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 930\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20053 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 51\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20054 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 192\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20055 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 190\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20056 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 169\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20057 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20058 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 12624\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20059 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 100525\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20060 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 59\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20061 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 323\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20062 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 0\n",
      "      noise sampling finished\n",
      "20063 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 1577\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20064 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 310\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20065 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 161\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20066 normal sampling finished\n",
      "      normal store finished       \n",
      "     count_total 7940\n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "sine, square, traingle finished\n"
     ]
    }
   ],
   "source": [
    "# get all subdir name in mitdb dir\n",
    "lydhdb = findSubdir('db/lydhdb')\n",
    "lydhdb.remove('lorenz_plots')\n",
    "lydhdb = sort(lydhdb)\n",
    "\n",
    "total_noise = 0\n",
    "\n",
    "with tf.io.TFRecordWriter('/tmpdata/val.tfrecords') as val_writer:\n",
    "    for i in range(0,9):\n",
    "        with tf.io.TFRecordWriter('/tmpdata/train_'+str(i+1)+'.tfrecords') as train_writer:\n",
    "            records = lydhdb[i*8:(i+1)*8] if i!=8 else lydhdb[i*8:]\n",
    "            for record in records:\n",
    "                path = 'db/lydhdb/'+record\n",
    "\n",
    "                R_set,R = annProcess(path) \n",
    "\n",
    "                x_normal, y_normal = sampling_normal(path,15500,10800,R_set,record) # sampling R and nR\n",
    "                print(record + ' normal sampling finished')\n",
    "                x_train, x_val, y_train, y_val = shuffle_and_split(x_normal, y_normal,seed = 10,size = 0.03)\n",
    "            \n",
    "                putSample(train_writer, len(x_train), x_train,y_train) # store samples to TFrecord\n",
    "                putSample(val_writer, len(x_val), x_val,y_val)\n",
    "                print('      normal store finished       ')  \n",
    "                \n",
    "                \n",
    "                x_noise, y_noise,count_noise = sampling_noise(path,R,record) # sampling true noise\n",
    "                total_noise+=count_noise\n",
    "                print('      noise sampling finished')\n",
    "                if len(x_noise)!=0:\n",
    "                    x_train, x_val, y_train, y_val = shuffle_and_split(x_noise,y_noise,seed = 10,size = 0.03)\n",
    "                    \n",
    "                    putSample(train_writer, len(x_train), x_train,y_train) # store samples to TFrecord\n",
    "                    putSample(val_writer, len(x_val), x_val,y_val)\n",
    "                    print('     noise store finished       ')  \n",
    "\n",
    "            if i==8:\n",
    "                x_sine,y_sine = get_sin(1,10) # store regular noise samples to TFrecord\n",
    "                x_square, y_square = get_square(1,10)\n",
    "                x_tran, y_tran = get_triangle(1,10)\n",
    "                putSample(train_writer, 747, x_sine,y_sine)\n",
    "                putSample(train_writer, 747, x_square, y_square)\n",
    "                putSample(train_writer, 747, x_tran, y_tran)\n",
    "                print('sine, square, traingle finished') \n",
    "\n",
    "        train_writer.close()\n",
    "val_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
