{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outline:\n",
    "\n",
    "~4,000,000 for training set + ~80,000 for validate set(no augment)\n",
    "\n",
    "1. Annotation:\n",
    "\n",
    "   1)  Read through ann.txt. For each R wave point, store its position to the corresponding set (R/A/V). If type is X, skip.\n",
    "   (annProcess)\n",
    "\n",
    "\n",
    "2. Sampling:\n",
    "\n",
    "   1) For each record in lydhdb, choose 18 segment(768 points). For each segment, using a sliding window(512 width) with 8 points step to obtain 256/ 8 = 32 samples. And create label for each sample.\n",
    "   \n",
    "   2) Obtain period with tiny QRS and period with heart block. Create label.\n",
    "   \n",
    "   3) Obtain true noise from each record. Create label\n",
    "   \n",
    "   4) Obtain regular noise(sine/square/triangle) with frequency ranging from 1 to 10 and different phases. Create label.\n",
    "\n",
    "\n",
    "3. Data Augmentation: \n",
    "\n",
    "   1) Segment 5 period(512 points) from em and ma noise record seperatively. Apply 2 different coefficients to the 10 segments -> obtain 5*2*2 = 20 noise segment in total. (noise_segment)\n",
    "\n",
    "\n",
    "4. Wavelet decomposition + Store as TFRecord\n",
    "    \n",
    "   1) Add each noise segment to each sampled sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from Stationary_transform import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''preprocess annotation file; \n",
    "   create set R: contains all R waves\n",
    "          set A: contains all atrial premature beats\n",
    "          set V: contains all ventricular premature beats'''\n",
    "\n",
    "def annProcess(path):\n",
    "    \n",
    "    with open(path+'/ann.txt','r') as f: # read annotation\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    R = set() # output initialize\n",
    "    A = set()\n",
    "    V = set()\n",
    "    \n",
    "    ecg = np.fromfile(path+'/ecg.dat', '>i2') # get ecg length\n",
    "    ecg_len = len(ecg)\n",
    "    \n",
    "    for line in lines: # add each R wave to corresponding set\n",
    "        temp = line.split(',')\n",
    "        pos,typ = temp[0],temp[1]\n",
    "        if typ == 'X':\n",
    "            continue\n",
    "        pos = round(int(pos)/1000*256) # convert time(ms) to index\n",
    "        R.add(pos) # R contains all type R waves (except X)\n",
    "        if typ =='A': # A contains all atrial premature beat\n",
    "            A.add(pos)\n",
    "        elif typ =='V': # V contains all ventricular premature beat\n",
    "            V.add(pos)\n",
    "    \n",
    "    return R,A,V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Creator Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''create label for samples containing R waves\n",
    "*** position in the label is the relative position to the grid with range from [0,1]\n",
    "'''\n",
    "\n",
    "def create_normal_label(sample, R):\n",
    "    label = np.empty((8,2),'float32') # label size (8,2) -> 8 grid. prob and pos x for each grid\n",
    "    for i in range(8):\n",
    "        found = False\n",
    "        for j in range(64): # loop through each point. Search point in R. If is R, label the grid with [1, relative pos]\n",
    "            pos = 64*i+j+sample[-1]-256\n",
    "            if pos in R:\n",
    "                label[i] = [1,j/64]\n",
    "                found = True\n",
    "        if not found: # if no R in the grid, label the grid with [0,-1]. -> -1 = no meaning\n",
    "            label[i] = [0,-1]\n",
    "    return label\n",
    "\n",
    "\n",
    "'''create label for true noise or regular noise samples'''\n",
    "\n",
    "def create_noise_label():\n",
    "    label = np.empty((8,2),'int')\n",
    "    label[:,0], label[:,1] = 0,-1   \n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling period with normal R waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Check if at least 1 R wave present in the period'''\n",
    "def validPeriod(n, R):\n",
    "    for i in range(256):\n",
    "        if n-i in R or n+i in R:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "'''sampling period without noise'''\n",
    "def sampling_normal(R,record,train_size,val_size,ecg):\n",
    "    \n",
    "    x_train,y_train = np.empty((train_size,514),'float32'),np.empty((train_size,8,2),'float32') # initialize output\n",
    "    x_val,y_val  = np.empty((val_size,514),'float32'),np.empty((val_size,8,2),'float32')\n",
    "    \n",
    "    selected,count,times = set(),0,train_size//32\n",
    "    \n",
    "    np.random.seed(40)            # Get sample for train set\n",
    "    seg_len = len(ecg)//times\n",
    "    for i in range(0,len(ecg),seg_len):\n",
    "        n = np.random.randint(i,i+seg_len) # choose a point in the segment, slide from n with step 8\n",
    "        for j in range(32):\n",
    "            if validPeriod(n,R):\n",
    "                sample = np.array([ecg[n-256:n+256]])\n",
    "                x = np.empty((514),'float32')\n",
    "                x[:512] = sample\n",
    "                x[-2:] = [record,n]\n",
    "                x_train[count] = x\n",
    "                y_train[count] = create_normal_label(x,R)\n",
    "                count += 1\n",
    "                selected.add(n)\n",
    "            n += 8\n",
    "            \n",
    "    np.random.seed(40) # Get sample for val set\n",
    "    count = 0\n",
    "    while count<val_size:\n",
    "        n = np.random.randint(256,len(ecg)-256) \n",
    "        if n not in selected and validPeriod(n,R):\n",
    "            x = np.empty((514),'float32')\n",
    "            x[:512] = np.array([ecg[n-256:n+256]])\n",
    "            x[-2:] = [record,n]\n",
    "            x_val[count] = x\n",
    "            y_val[count] = create_normal_label(x,R)\n",
    "            count+=1\n",
    "        selected.add(n)\n",
    "\n",
    "    return x_train, x_val, y_train, y_val "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Premature Beat Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''sampling period with A'''\n",
    "\n",
    "def sampling_A(R,A,record,train_size,val_size,ecg):\n",
    "    \n",
    "    x_train,y_train = np.empty((train_size,514),'float32'),np.empty((train_size,8,2),'float32') # initialize output\n",
    "    x_val,y_val  = np.empty((val_size,514),'float32'),np.empty((val_size,8,2),'float32')\n",
    "    \n",
    "    selected, count= set(), 0 # Get sample for train set\n",
    "    np.random.seed(40) \n",
    "    A = np.fromiter(A, 'int')\n",
    "    while count < train_size:\n",
    "        n = random.choice(A)\n",
    "        if n not in selected:\n",
    "            for i in range(n-256-128,n-256,8): # 16 windows\n",
    "                x = np.empty((514),'float32')\n",
    "                x[:512] = np.array([ecg[i:i+512]])\n",
    "                x[-2:] = [record,i+256]\n",
    "                x_train[count] = x\n",
    "                y_train[count] = create_normal_label(x,R)\n",
    "                count+=1\n",
    "            selected.add(n)\n",
    "    \n",
    "    count = 0\n",
    "    while count<val_size:  # Get sample for val set\n",
    "        n = random.choice(A)\n",
    "        if n not in selected:\n",
    "            for i in range(n-256-128,n-256,16): #8 windows\n",
    "                x = np.empty((514),'float32')\n",
    "                x[:512] = np.array([ecg[i:i+512]])\n",
    "                x[-2:] = [record,i+256]\n",
    "                x_val[count] = x\n",
    "                y_val[count] = create_normal_label(x,R)\n",
    "                count+=1\n",
    "            selected.add(n)\n",
    "    \n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''sampling period with V'''\n",
    "\n",
    "def sampling_V(R,V,record,train_size,val_size,ecg):\n",
    "    \n",
    "    x_train,y_train = np.empty((train_size,514),'float32'),np.empty((train_size,8,2),'float32') # initialize output\n",
    "    x_val,y_val  = np.empty((val_size,514),'float32'),np.empty((val_size,8,2),'float32')\n",
    "    \n",
    "    selected,count = set(),0\n",
    "    np.random.seed(40)\n",
    "    V = np.fromiter(V, 'int')\n",
    "    while count<train_size:  # Get sample for train set\n",
    "        n = random.choice(V)\n",
    "        if n not in selected:\n",
    "            for i in range(n-256-128,n-128,8): # 32 windows\n",
    "                x = np.empty((514),'float32')\n",
    "                x[:512] = np.array([ecg[i:i+512]])\n",
    "                x[-2:] = [record,i+256]\n",
    "                x_train[count] = x\n",
    "                y_train[count] = create_normal_label(x,R)\n",
    "                count+=1\n",
    "            selected.add(n)\n",
    "            \n",
    "    count = 0\n",
    "    while count<val_size:  # Get sample for val set\n",
    "        n = random.choice(V)\n",
    "        if n not in selected:\n",
    "            for i in range(n-256-128,n-256,16): # 8 windows\n",
    "                x = np.empty((514),'float32')\n",
    "                x[:512] = np.array([ecg[i:i+512]])\n",
    "                x[-2:] = [record,i+256]\n",
    "                x_val[count] = x\n",
    "                y_val[count] = create_normal_label(x,R)\n",
    "                count+=1\n",
    "            selected.add(n)\n",
    "    \n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Heart Block Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_block(R,record,train_size,val_size,ecg):\n",
    "    \n",
    "    x_train,y_train = np.empty((train_size,514),'float32'),np.empty((train_size,8,2),'float32') # initialize output\n",
    "    x_val,y_val  = np.empty((val_size,514),'float32'),np.empty((val_size,8,2),'float32')\n",
    "    \n",
    "    selected,count,times = set(),0,train_size//32\n",
    "    \n",
    "    np.random.seed(40)            # Get sample for train set\n",
    "    seg_len = len(ecg)//times\n",
    "    for i in range(0,len(ecg),seg_len):\n",
    "        n = np.random.randint(i,i+seg_len) # choose a point in the segment, slide from n with step 8\n",
    "        for j in range(32):\n",
    "            if validPeriod(n,R):\n",
    "                x = np.empty((514),'float32')\n",
    "                x[:512] = np.array([ecg[n-256:n+256]])\n",
    "                x[-2:] = [record,n]\n",
    "                x_train[count] = x\n",
    "                y_train[count] = create_normal_label(x,R)\n",
    "                count += 1\n",
    "            selected.add(n)\n",
    "            n += 8\n",
    "            \n",
    "    np.random.seed(40)            # Get sample for val set\n",
    "    count = 0\n",
    "    while count<val_size:\n",
    "        n = np.random.randint(256,len(ecg)-256) \n",
    "        if n not in selected and validPeriod(n,R):\n",
    "            x = np.empty((514),'float32')\n",
    "            x[:512] = np.array([ecg[n-256:n+256]])\n",
    "            x[-2:] = [record,n]\n",
    "            x_val[count] = x\n",
    "            y_val[count] = create_normal_label(x,R)\n",
    "            count+=1\n",
    "        selected.add(n)\n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Tiny Wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary(boundary, t0):\n",
    "    sample_boundary = np.empty((len(boundary),2),'int')\n",
    "\n",
    "    for i,period in enumerate(boundary):\n",
    "        start,end = period[0],period[1]\n",
    "        start = time.strptime(start,'%Y-%m-%d %H:%M:%S')\n",
    "        end = time.strptime(end, '%Y-%m-%d %H:%M:%S')\n",
    "        start,end = time.mktime(start),time.mktime(end)\n",
    "        start,end = int((start-t0)*256), int((end-t0)*256)\n",
    "        sample_boundary[i] = [start,end]\n",
    "    return sample_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_tiny(R,sample_boundary,record,train_size,val_size,ecg):\n",
    "\n",
    "    data_x,data_y = np.empty((train_size+val_size,514),'float32'),np.empty((train_size+val_size,8,2),'float32') \n",
    "    \n",
    "    count = 0\n",
    "    for boundary in sample_boundary:\n",
    "        start,end = boundary[0],boundary[1]\n",
    "        for n in range(start+256,end-256,4):\n",
    "            x = np.empty((514),'float32')\n",
    "            x[:512] = np.array([ecg[n-256:n+256]])\n",
    "            x[-2:] = [record,n]\n",
    "            data_x[count] = x\n",
    "            data_y[count] = create_normal_label(x,R)\n",
    "            count+=1\n",
    "            \n",
    "    data_x,data_y = np.copy(data_x[:count]),np.copy(data_y[:count]) # make copy to avoid memory leak\n",
    "            \n",
    "    return data_x,data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling True Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''sampling true noise from each record'''\n",
    "\n",
    "def sampling_noise(R,record,ecg): \n",
    "    \n",
    "    R = sorted(list(R))\n",
    "    data_x,data_y = np.empty((150000,514),'float32'),np.empty((150000,8,2),'int') # initialize output\n",
    "    # 150000 is an abitrary large number. It is used cuz exact number of noise in the record is unknown\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for i, loc in enumerate(R[1:]):\n",
    "        dis=loc-R[i]\n",
    "        if dis>1064 and count<150000: #1064 considered +-20 of the R peak\n",
    "            for n in range(R[i]+257,loc-257,25):\n",
    "                x = np.empty((514),'float32')\n",
    "                x[:512] = np.array([ecg[n-256:n+256]])\n",
    "                x[-2:] = [record,n]\n",
    "                data_x[count] = x\n",
    "                data_y[count] = create_noise_label() \n",
    "                count+=1\n",
    "\n",
    "    if count ==0: # when no noise in the record\n",
    "        return [],[],0\n",
    "    \n",
    "    x_noise,y_noise = np.copy(data_x[:count]),np.copy(data_y[:count]) # make copy to avoid memory leak\n",
    "    del data_x\n",
    "    del data_y\n",
    "    \n",
    "    return x_noise,y_noise,count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Regular Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create sine/square/triangle waves as regular noise'''\n",
    "\n",
    "def get_sin(freq_low, freq_high, size=747):\n",
    "    \n",
    "    data_x, data_y = np.empty((size,514),'float32'),np.empty((size,8,2),'int') \n",
    "    \n",
    "    count = 0\n",
    "    time_axis = np.arange(512)\n",
    "    for freq in range(freq_low, freq_high+1): # get sine with multiple frequency and phase\n",
    "        B = 2*np.pi*freq/256\n",
    "        for phi in range(int(256/freq)):\n",
    "            print('Get sine '+str(count)+'/ '+str(size), end = '\\r')\n",
    "            sine = np.sin(B*time_axis-B*phi)\n",
    "            data_x[count] = append(sine,[0,0])\n",
    "            data_y[count] = create_noise_label()\n",
    "            count+=1 \n",
    "    return data_x,data_y\n",
    "    \n",
    "    \n",
    "def get_square(freq_low, freq_high, size=747):\n",
    "    data_x, data_y = np.empty((size,514),'float32'),np.empty((size,8,2),'int') # initialize output\n",
    "    count = 0\n",
    "    \n",
    "    for freq in range(freq_low, freq_high+1):\n",
    "        square = np.zeros(1024,'float32') # generate square wave wiht length 1024, but will only crop 512 segment from it\n",
    "        length,pos,i = int(256/(2*freq)),1,0\n",
    "        while i< 4*2*freq:\n",
    "            square[i*length:(i+1)*length] = np.ones(length,'int')*pos\n",
    "            pos *= -1\n",
    "            i+=1 \n",
    "        for phi in range(int(256/freq)): # sliding window to crop the length 512 from square wave according to phase\n",
    "            print('Get square '+str(count)+'/ '+str(size), end = '\\r')\n",
    "            data_x[count]=np.append(square[phi:phi+512],[0,0])\n",
    "            data_y[count] = create_noise_label()\n",
    "            count+=1\n",
    "    return data_x, data_y\n",
    "    \n",
    "    \n",
    "def get_triangle(freq_low, freq_high,size=747):\n",
    "    data_x, data_y = np.empty((size,514),'float32'),np.empty((size,8,2),'int') # initialize output\n",
    "    count = 0\n",
    "    \n",
    "    for freq in range(freq_low, freq_high+1):\n",
    "        tran = np.zeros(1024,'float32') # generate triangle wave wiht length 1024, but will only crop 512 segment from it\n",
    "        slope, part, period = 1/(256/(4*freq)), 256/(4*freq), 256//freq\n",
    "        for i in range(256//freq): # draw triangle wave with length 256\n",
    "            m = 256/(4*freq)\n",
    "            if (i//(256/(4*freq)))%4==0:\n",
    "                tran[i] = slope*i\n",
    "            elif (i//(256/(4*freq)))%4==3:\n",
    "                tran[i] = slope*i+(-1-slope*(3*part))\n",
    "            else:\n",
    "                tran[i] = -slope*i+slope*(part*2)\n",
    "        for i in range(1,4*freq): # copy length 256 for multi-times to make full 1024 length wave\n",
    "            tran[i*period:(i+1)*period] = tran[:period]\n",
    "\n",
    "        for phi in range(int(256/freq)): # sliding window to crop the length 512 from square wave according to phase\n",
    "            data_x[count]=np.append(tran[phi:phi+512],[0,0])\n",
    "            data_y[count] = create_noise_label()\n",
    "            count+=1\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Obtain noise segments from em and ma noise record'''\n",
    "\n",
    "def noise_segment(coefficient, em_path = 'Record/em.dat', ma_path = 'Record/ma.dat'):\n",
    "    em = np.fromfile(em_path,'>i2') # upload noise record \n",
    "    ma = np.fromfile(ma_path,'>i2')\n",
    "    \n",
    "    noise_sample = np.empty((20,1024),'float32') #[em1_1,em1_2,ma1_1,ma1_2...,em5_1,em5_2,ma5_1,ma5_2]\n",
    "    orig_noise = np.empty((10,1024),'float32') #[em1,ma1,em2,ma2,..., em5,ma5]\n",
    "    \n",
    "    # randomly obtained 5 noise samples from em and ma seperatively and stored in orig_noise\n",
    "    start,end,step,index = len(em)//5//2,len(em),len(em)//5,0 \n",
    "    for n in range(start,end,step):\n",
    "        sample_em = em[n-512:n+512]\n",
    "        orig_noise[index] = sample_em\n",
    "        sample_ma = ma[n-512:n+512]\n",
    "        orig_noise[index+1] = sample_ma\n",
    "        index+=2\n",
    "        \n",
    "    # for each noise sample obtained, applied coefficient to it and stored in noise_sample\n",
    "    index = 0\n",
    "    for i,noise in enumerate(orig_noise):\n",
    "        for e in coefficient[i]:\n",
    "            noise_sample[index] = noise*e\n",
    "            index+=1\n",
    "    \n",
    "    return noise_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_large_noise():\n",
    "    \n",
    "    large_noise = np.empty((10,768),'float32')\n",
    "    tmp = np.fromfile('db/lydhdb/20009/ecg.dat', '>i2')\n",
    "    \n",
    "    noise = np.zeros((768),'float32')\n",
    "    noise[384-50:384+50] = tmp[177930:178030]\n",
    "    large_noise[0] = noise\n",
    "    \n",
    "    noise = np.zeros((768),'float32')\n",
    "    noise[384-40:384+25] = tmp[7190:7255]\n",
    "    large_noise[1] = noise\n",
    "    \n",
    "    noise = np.zeros((768),'float32')\n",
    "    noise[384-5:384+18] = tmp[7910:7933]\n",
    "    large_noise[2] = noise\n",
    "    \n",
    "    noise = np.zeros((768),'float32')\n",
    "    noise[384-40:384+10] = tmp[10265:10315]\n",
    "    large_noise[2] = noise\n",
    "    \n",
    "    noise = np.zeros((768),'float32')\n",
    "    noise[384-22:384+20] = tmp[10928:10970]\n",
    "    large_noise[3] = noise\n",
    "                                               ### not finish\n",
    "    return large_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation and TFRecord Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Do stationary wavelet decomposition;\n",
    "   Save samples to tfrecord file'''\n",
    "\n",
    "def putSample(writer, size, data_x, data_y):\n",
    "    for i in range(size):\n",
    "        y = data_y[i].reshape(16)\n",
    "        \n",
    "        sample = decomp(data_x[i][:-2],'db2',(512,8)).reshape(4096) # stationary wavelet decomposition using db wavelet\n",
    "        x = np.empty((4098),'float32')\n",
    "        x[:4096] = sample\n",
    "        x[-2:] = data_x[i][-2:]\n",
    "\n",
    "        # create example and write to tfrecord\n",
    "        feature = {\n",
    "            'ecg': tf.train.Feature(float_list=tf.train.FloatList(value=x)),\n",
    "            'label': tf.train.Feature(float_list=tf.train.FloatList(value=y)),\n",
    "        }\n",
    "        example = tf.train.Example(features = tf.train.Features(feature = feature))\n",
    "        writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Add em/ma noise to each sample;\n",
    "   Do stationary wavelet decomposition on each sample;\n",
    "   Save samples to tfrecord file'''\n",
    "\n",
    "def putSample_AddNoise(writer, size, data_x, data_y, noise_sample):\n",
    "    for i in range(size):\n",
    "        y = data_y[i].reshape(16)\n",
    "        for noise in noise_sample:\n",
    "            n = np.random.randint(256,768)\n",
    "            noise = noise[n-256:n+256]\n",
    "            sample = decomp(data_x[i][:-2]+noise,'db2',(512,8)).reshape(4096) #stationary wavelet decomposition using db wavelet\n",
    "            x = np.empty((4098),'float32')\n",
    "            x[:4096] = sample\n",
    "            x[-2:] = data_x[i][-2:]\n",
    "\n",
    "            # # create example and write to tfrecord\n",
    "            feature = {\n",
    "                'ecg': tf.train.Feature(float_list=tf.train.FloatList(value=x)),\n",
    "                'label': tf.train.Feature(float_list=tf.train.FloatList(value=y)),\n",
    "            }\n",
    "            example = tf.train.Example(features = tf.train.Features(feature = feature))\n",
    "            writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def putSample_LargeNoise(writer, size, data_x, data_y, large_noise):\n",
    "    for i in range(size):\n",
    "        y = data_y[i].reshape(16)\n",
    "        for noise in large_noise:\n",
    "            n = np.random.randint(256,512)\n",
    "            noise = noise[n-256:n+256]\n",
    "            sample = decomp(data_x[i][:-2]+noise,'db2',(512,8)).reshape(4096) #stationary wavelet decomposition using db wavelet\n",
    "            x = np.empty((4098),'float32')\n",
    "            x[:4096] = sample\n",
    "            x[-2:] = data_x[i][-2:]\n",
    "\n",
    "            # # create example and write to tfrecord\n",
    "            feature = {\n",
    "                'ecg': tf.train.Feature(float_list=tf.train.FloatList(value=x)),\n",
    "                'label': tf.train.Feature(float_list=tf.train.FloatList(value=y)),\n",
    "            }\n",
    "            example = tf.train.Example(features = tf.train.Features(feature = feature))\n",
    "            writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle x and y; split to val set/train set\n",
    "def shuffle_and_split(data_x,data_y,seed = 10,size = 0.03):\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(data_x)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(data_y)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(data_x,data_y, test_size=0.03)\n",
    "    return x_train, x_val, y_train, y_val\n",
    "\n",
    "\n",
    "# get the name of each record folder\n",
    "def findSubdir(path):\n",
    "    subdir = [x for x in os.walk(path)]\n",
    "    subdir[0][1].remove('lorenz_plots')\n",
    "    return subdir[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineCoefficient():\n",
    "    em1 = [0.2,0.5] # coefficient for each em/ma noise segment\n",
    "    em2 = [0.1,0.15]\n",
    "    em3 = [0.2,0.5]\n",
    "    em4 = [0.1,0.3]\n",
    "    em5 = [0.1,0.2]\n",
    "\n",
    "    ma1 = [0.3,0.7]\n",
    "    ma2 = [0.5,1.3]\n",
    "    ma3 = [0.5,1.4]\n",
    "    ma4 = [1,4]\n",
    "    ma5 = [0.5,1.3]\n",
    "    coefficient = np.array([em1,ma1,em2,ma2,em3,ma3,em4,ma4,em5,ma5])\n",
    "    return coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineTiny():\n",
    "\n",
    "    # location of tiny wave sample\n",
    "    record_boundary,t0 = {},{}\n",
    "\n",
    "    # 20020\n",
    "    t0['20020'] = time.mktime(time.strptime('2000-8-21 9:40:56','%Y-%m-%d %H:%M:%S'))\n",
    "    boundary_20020 = [['2000-8-21 9:42:13','2000-8-21 9:43:20'],['2000-8-21 9:48:24','2000-8-21 9:54:58'],\n",
    "                ['2000-8-21 14:2:0','2000-8-21 14:3:0'],['2000-8-21 19:55:00','2000-8-21 19:56:14'],\n",
    "                ['2000-8-21 20:32:41','2000-8-21 20:33:46'],['2000-8-22 2:47:32','2000-8-22 2:57:00'],\n",
    "                ['2000-8-22 3:11:54','2000-8-22 3:12:39'],['2000-8-22 3:16:40','2000-8-22 3:18:00'],\n",
    "                ['2000-8-22 3:19:10','2000-8-22 3:20:00'],['2000-8-22 4:22:20','2000-8-22 4:30:54'],\n",
    "                ['2000-8-22 4:33:25','2000-8-22 4:33:33'],['2000-8-22 4:50:38','2000-8-22 4:53:00'],\n",
    "                ['2000-8-22 5:1:19','2000-8-22 5:1:30'],['2000-8-22 5:1:48','2000-8-22 5:1:56'],\n",
    "                ['2000-8-22 5:3:22','2000-8-22 5:3:32'],['2000-8-22 5:11:41','2000-8-22 5:11:48'],\n",
    "                ['2000-8-22 5:17:19','2000-8-22 5:17:22'],['2000-8-22 5:43:23','2000-8-22 5:43:30'],\n",
    "                ['2000-8-22 6:32:22', '2000-8-22 6:33:02'],['2000-8-22 6:59:44','2000-8-22 6:59:53'],\n",
    "                ['2000-8-22 7:54:53','2000-8-22 7:55:03']]\n",
    "    record_boundary['20020'] = boundary_20020\n",
    "\n",
    "    # 20010\n",
    "    t0['20010'] = time.mktime(time.strptime('2000-8-21 10:42:3','%Y-%m-%d %H:%M:%S'))\n",
    "    boundary_20010 = [['2000-8-21 11:02:10','2000-8-21 11:4:0'],['2000-8-21 11:04:32','2000-8-21 11:05:32'],\n",
    "                ['2000-8-21 11:06:0','2000-8-21 11:06:8'],['2000-8-21 13:41:02','2000-8-21 13:41:52'],\n",
    "                ['2000-8-21 13:42:54','2000-8-21 13:43:14'],['2000-8-21 13:43:20','2000-8-21 13:43:33'],\n",
    "                ['2000-8-21 13:43:43','2000-8-21 13:44:11'],['2000-8-21 13:47:57','2000-8-21 13:48:57'],\n",
    "                ['2000-8-21 13:49:34','2000-8-21 13:49:45'],['2000-8-21 13:50:56','2000-8-21 13:52:20'],\n",
    "                ['2000-8-21 13:53:47','2000-8-21 13:58:0'],['2000-8-21 16:42:34','2000-8-21 16:50:27'],\n",
    "                ['2000-8-22 4:15:6', '2000-8-22 4:15:49'],['2000-8-22 4:58:00','2000-8-22 4:59:00'],\n",
    "                ['2000-8-22 5:14:0','2000-8-22 5:16:0'],['2000-8-22 5:29:30','2000-8-22 5:31:0'],\n",
    "                ['2000-8-22 7:29:45','2000-8-22 7:32:45'],['2000-8-22 7:33:20','2000-8-22 7:36:30'],\n",
    "                ['2000-8-22 7:36:34','2000-8-22 7:43:21']]\n",
    "    record_boundary['20010'] = boundary_20010\n",
    "\n",
    "    # 20029\n",
    "    t0['20029'] = time.mktime(time.strptime('2000-8-21 14:37:32','%Y-%m-%d %H:%M:%S'))\n",
    "    boundary_20029 = [['2000-8-21 14:42:04','2000-8-21 14:45:17'],['2000-8-21 14:45:32','2000-8-21 14:48:26'],\n",
    "                ['2000-8-21 15:1:30','2000-8-21 15:8:11'],['2000-8-21 15:15:33','2000-8-21 15:16:26'],\n",
    "                ['2000-8-21 15:35:5','2000-8-21 15:35:50'],['2000-8-21 16:18:50','2000-8-21 16:20:00'],\n",
    "                ['2000-8-21 16:56:15','2000-8-21 17:13:21'],['2000-8-21 17:14:50','2000-8-21 17:15:40']]\n",
    "    record_boundary['20029'] = boundary_20029\n",
    "\n",
    "    # 20058\n",
    "    t0['20058'] = time.mktime(time.strptime('2000-8-21 15:38:25','%Y-%m-%d %H:%M:%S'))\n",
    "    boundary_20058 = [['2000-8-22 8:16:40','2000-8-22 8:35:0'],['2000-8-22 8:36:00','2000-8-22 8:38:40'],\n",
    "                ['2000-8-22 8:39:27','2000-8-22 8:42:33'],['2000-8-22 8:8:5','2000-8-22 8:11:24'],\n",
    "                ['2000-8-22 7:53:58','2000-8-22 7:59:7']]\n",
    "    record_boundary['20058'] = boundary_20058\n",
    "    \n",
    "    return record_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(database_path = 'db/lydhdb', output_path = '/tmpdata/',trainfile_num = 9):\n",
    "    \n",
    "    record_boundary = defineTiny()\n",
    "    database = findSubdir(database_path) # get all record folder name\n",
    "    database = sorted(database)\n",
    "\n",
    "    block = ['20017','20031','20048','20066']\n",
    "    tiny = ['20020','20010','20029','20058']\n",
    "\n",
    "    normal = [i for i in database if i not in block]\n",
    "    normal = [i for i in normal if i not in tiny]\n",
    "\n",
    "    with tf.io.TFRecordWriter(output_path + 'val.tfrecords') as val_writer:\n",
    "        noise_sample = noise_segment(defineCoefficient())\n",
    "        large_noise = get_large_noise()\n",
    "        for i in range(0,trainfile_num):\n",
    "            with tf.io.TFRecordWriter(output_path +'train_'+str(i+1)+'.tfrecords') as train_writer:\n",
    "                record_num = math.ceil(len(database)/trainfile_num)\n",
    "                records = database[i*record_num:(i+1)*record_num] if i!=trainfile_num-1 else database[i*record_num:]\n",
    "                for record in records:\n",
    "                    path = database_path+'/'+record\n",
    "                    ecg = np.fromfile(path +'/ecg.dat', '>i2') # load ecg\n",
    "\n",
    "                    R,A,V = annProcess(path) \n",
    "                    \n",
    "                    print(record)\n",
    "\n",
    "                    if record in normal:\n",
    "                        x_train, x_val, y_train, y_val = sampling_normal(R,record,800,475,ecg) # sampling \n",
    "                        putSample_AddNoise(train_writer, len(x_train), x_train,y_train,noise_sample) # store to TFrecord\n",
    "                        putSample_LargeNoise(train_writer, len(x_train), x_train,y_train, large_noise)\n",
    "                        putSample(train_writer,len(x_train),x_train,y_train)\n",
    "                        putSample(val_writer, len(x_val), x_val,y_val)\n",
    "                    print('      normal store finished       ')  \n",
    "\n",
    "                    if len(A)>=14: # sampling period with A\n",
    "                        x_train, x_val, y_train, y_val = sampling_A(R,A,record,int(len(A)*0.075)*16,int(len(A)*0.089)*8,ecg)\n",
    "                        putSample_AddNoise(train_writer,len(x_train),x_train,y_train,noise_sample)\n",
    "                        putSample_LargeNoise(train_writer, len(x_train), x_train,y_train, large_noise)\n",
    "                        putSample(train_writer,len(x_train),x_train,y_train)\n",
    "                        putSample(val_writer, len(x_val), x_val,y_val)\n",
    "\n",
    "                    if len(V)>=50: # sampling period with V\n",
    "                        x_train, x_val, y_train, y_val = sampling_V(R,V,record,int(len(V)*0.0176)*32,int(len(V)*0.042)*8,ecg)\n",
    "                        putSample_AddNoise(train_writer,len(x_train),x_train,y_train,noise_sample)\n",
    "                        putSample_LargeNoise(train_writer, len(x_train), x_train,y_train, large_noise)\n",
    "                        putSample(train_writer,len(x_train),x_train,y_train)\n",
    "                        putSample(val_writer, len(x_val), x_val,y_val)\n",
    "                    print('      premature beat store finished       ')\n",
    "\n",
    "                    if record in block:\n",
    "                        x_train, x_val, y_train, y_val = sampling_block(R,record,2976,1750,ecg)\n",
    "                        putSample_AddNoise(train_writer, len(x_train), x_train,y_train,noise_sample) # store to TFrecord\n",
    "                        putSample_LargeNoise(train_writer, len(x_train), x_train,y_train, large_noise)\n",
    "                        putSample(train_writer,len(x_train),x_train,y_train)\n",
    "                        putSample(val_writer, len(x_val), x_val,y_val)\n",
    "                    print('      block store finished       ')  \n",
    "\n",
    "                    if record in tiny: \n",
    "                        sample_boundary = get_boundary(record_boundary[record], t0[record])\n",
    "                        data_x,data_y = sampling_tiny(R,sample_boundary,record,150000,3000,ecg)\n",
    "                        x_train, x_val, y_train, y_val = train_test_split(data_x,data_y, test_size=0.0186,shuffle = False)\n",
    "                        putSample(train_writer,len(x_train),x_train,y_train)\n",
    "                        putSample(val_writer, len(x_val), x_val,y_val)\n",
    "                    print('      tiny wave store finished       ')\n",
    "\n",
    "                    x_noise, y_noise,count_noise = sampling_noise(R,record,ecg) # sampling true noise sample\n",
    "                    if len(x_noise)!=0:\n",
    "                        x_train, x_val, y_train, y_val = shuffle_and_split(x_noise,y_noise,seed = 10,size = 0.03)\n",
    "                        putSample(train_writer, len(x_train), x_train,y_train) # store train sample to TFrecord\n",
    "                        putSample(val_writer, len(x_val), x_val,y_val)\n",
    "                        print('      noise store finished       ')  \n",
    "\n",
    "                if i==8: # get regular noise\n",
    "                    x_sine,y_sine = get_sin(1,10)\n",
    "                    x_square, y_square = get_square(1,10)\n",
    "                    x_tran, y_tran = get_triangle(1,10)\n",
    "                    putSample(train_writer, 747, x_sine,y_sine)\n",
    "                    putSample(train_writer, 747, x_square, y_square)\n",
    "                    putSample(train_writer, 747, x_tran, y_tran)\n",
    "                    print('sine, square, traingle finished') \n",
    "\n",
    "            train_writer.close()\n",
    "    val_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
