{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outline:\n",
    "\n",
    "~2,000,000 for training set + ~80,000 for validate set(no augment)\n",
    "\n",
    "1. Annotation:\n",
    "\n",
    "   1)  Read through ann.txt. For each R wave point, store its position to the corresponding set (R/A/V). If type is X, skip.\n",
    "   (annProcess)\n",
    "\n",
    "\n",
    "2. Sampling:\n",
    "\n",
    "   1) For each record in lydhdb, choose 18 segment(768 points). For each segment, using a sliding window(512 width) with 8 points step to obtain 256/ 8 = 32 samples. And create label for each sample.\n",
    "   \n",
    "   2) Obtain true noise from each record. Create label\n",
    "   \n",
    "   3) Obtain regular noise(sine/square/triangle) with frequency ranging from 1 to 10 and different phases. Create label.\n",
    "\n",
    "\n",
    "3. Data Augmentation: \n",
    "\n",
    "   1) Segment 5 period(512 points) from em and ma noise record seperatively. Apply 2 different coefficients to the 10 segments -> obtain 5*2*2 = 20 noise segment in total. (noise_segment)\n",
    "\n",
    "\n",
    "4. Wavelet decomposition + Store as TFRecord\n",
    "    \n",
    "   1) Add each noise segment to each sampled sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from Stationary_transform import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''preprocess annotation file; \n",
    "   create set R: contains all R waves\n",
    "          set A: contains all atrial premature beats\n",
    "          set V: contains all ventricular premature beats'''\n",
    "\n",
    "def annProcess(path):\n",
    "    \n",
    "    with open(path+'/ann.txt','r') as f: # read annotation\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    R = set() # output initialize\n",
    "    A = set()\n",
    "    V = set()\n",
    "    \n",
    "    ecg = np.fromfile(path+'/ecg.dat', '>i2') # get ecg length\n",
    "    ecg_len = len(ecg)\n",
    "    \n",
    "    for line in lines: # add each R wave to corresponding set\n",
    "        temp = line.split(',')\n",
    "        pos,typ = temp[0],temp[1]\n",
    "        if typ == 'X':\n",
    "            continue\n",
    "        pos = round(int(pos)/1000*256) # convert time(ms) to index\n",
    "        R.add(pos) # R contains all type R waves (except X)\n",
    "        if typ =='A': # A contains all atrial premature beat\n",
    "            A.add(pos)\n",
    "        elif typ =='V': # V contains all ventricular premature beat\n",
    "            V.add(pos)\n",
    "    \n",
    "    return R,A,V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Creator Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''create label for samples containing R waves\n",
    "*** position in the label is the relative position to the grid with range from [0,1]\n",
    "'''\n",
    "\n",
    "def create_normal_label(sample, R):\n",
    "    label = np.empty((8,2),'float32') # label size (8,2) -> 8 grid. prob and pos x for each grid\n",
    "    for i in range(8):\n",
    "        found = False\n",
    "        for j in range(64): # loop through each point. Search point in R. If is R, label the grid with [1, relative pos]\n",
    "            pos = 64*i+j+sample[-1]-256\n",
    "            if pos in R:\n",
    "                label[i] = [1,j/64]\n",
    "                found = True\n",
    "        if not found: # if no R in the grid, label the grid with [0,-1]. -> -1 = no meaning\n",
    "            label[i] = [0,-1]\n",
    "    return label\n",
    "\n",
    "\n",
    "'''create label for true noise or regular noise samples'''\n",
    "\n",
    "def create_noise_label():\n",
    "    label = np.empty((8,2),'int')\n",
    "    label[:,0], label[:,1] = 0,-1   \n",
    "    return label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling period with R waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Check if at least 1 R wave present in the period'''\n",
    "def validPeriod(n, R):\n",
    "    for i in range(256):\n",
    "        if n-i in R or n+i in R:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "'''sampling period without noise'''\n",
    "def sampling_normal(path,R,record,train_size,val_size):\n",
    "    ecg = np.fromfile(path +'/ecg.dat', '>i2') # load ecg \n",
    "    \n",
    "    x_train,y_train = np.empty((train_size,514),'float32'),np.empty((train_size,8,2),'float32') # initialize output\n",
    "    x_val,y_val  = np.empty((val_size,514),'float32'),np.empty((val_size,8,2),'float32')\n",
    "    \n",
    "    selected,count,times = set(),0,train_size//32\n",
    "    \n",
    "    # 把ECG平分成 ‘times’个部分，并在每个部分做滑窗，取得32个样本\n",
    "    start,end,step = len(ecg)//times//2,len(ecg),len(ecg)//times # Get sample for train set\n",
    "    for n in range(start,end,step):\n",
    "        for i in range(32): # 32 windows\n",
    "            sample = ecg[n+i*8-256:n+i*8+256]\n",
    "            x = np.empty((514),'float32')\n",
    "            x[:512] = sample\n",
    "            x[-2:] = [record,n+i*8]\n",
    "            x_train[count] = x\n",
    "            y_train[count] = create_normal_label(x,R)\n",
    "            selected.add(n+i*8) # memorize all points have been selected\n",
    "            count+=1\n",
    "            \n",
    "    np.random.seed(40) # Get sample for val set\n",
    "    count = 0\n",
    "    while count<val_size:\n",
    "        n = np.random.randint(256,len(ecg)-256) \n",
    "        if n not in selected and validPeriod(n,R):\n",
    "            x = np.empty((514),'float32')\n",
    "            x[:512] = np.array([ecg[n-256:n+256]])\n",
    "            x[-2:] = [record,n]\n",
    "            x_val[count] = x\n",
    "            y_val[count] = create_normal_label(x,R)\n",
    "            count+=1\n",
    "        selected.add(n)\n",
    "\n",
    "    return x_train, x_val, y_train, y_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''sampling period with A'''\n",
    "\n",
    "def sampling_A(path,R,A,record,train_size,val_size):\n",
    "    ecg = np.fromfile(path +'/ecg.dat', '>i2') # load ecg \n",
    "    \n",
    "    x_train,y_train = np.empty((train_size,514),'float32'),np.empty((train_size,8,2),'float32') # initialize output\n",
    "    x_val,y_val  = np.empty((val_size,514),'float32'),np.empty((val_size,8,2),'float32')\n",
    "    \n",
    "    selected, count= set(), 0 # Get sample for train set\n",
    "    np.random.seed(40) \n",
    "    A = np.fromiter(A, 'int')\n",
    "    while count < train_size:\n",
    "        n = random.choice(A)\n",
    "        if n not in selected:\n",
    "            for i in range(n-256-128,n-256,8): # 16 windows\n",
    "                x = np.empty((514),'float32')\n",
    "                x[:512] = np.array([ecg[i:i+512]])\n",
    "                x[-2:] = [record,i+256]\n",
    "                x_train[count] = x\n",
    "                y_train[count] = create_normal_label(x,R)\n",
    "                count+=1\n",
    "            selected.add(n)\n",
    "    \n",
    "    count = 0\n",
    "    while count<val_size:  # Get sample for val set\n",
    "        n = random.choice(A)\n",
    "        if n not in selected:\n",
    "            for i in range(n-256-128,n-256,16): #8 windows\n",
    "                x = np.empty((514),'float32')\n",
    "                x[:512] = np.array([ecg[i:i+512]])\n",
    "                x[-2:] = [record,i+256]\n",
    "                x_val[count] = x\n",
    "                y_val[count] = create_normal_label(x,R)\n",
    "                count+=1\n",
    "            selected.add(n)\n",
    "    \n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''sampling period with V'''\n",
    "\n",
    "def sampling_V(path,R,V,record,train_size,val_size):\n",
    "    ecg = np.fromfile(path +'/ecg.dat', '>i2') # load ecg \n",
    "    \n",
    "    x_train,y_train = np.empty((train_size,514),'float32'),np.empty((train_size,8,2),'float32') # initialize output\n",
    "    x_val,y_val  = np.empty((val_size,514),'float32'),np.empty((val_size,8,2),'float32')\n",
    "    \n",
    "    selected,count = set(),0\n",
    "    np.random.seed(40)\n",
    "    V = np.fromiter(V, 'int')\n",
    "    while count<train_size:  # Get sample for train set\n",
    "        n = random.choice(V)\n",
    "        if n not in selected:\n",
    "            for i in range(n-256-128,n-128,8): # 32 windows\n",
    "                x = np.empty((514),'float32')\n",
    "                x[:512] = np.array([ecg[i:i+512]])\n",
    "                x[-2:] = [record,i+256]\n",
    "                x_train[count] = x\n",
    "                y_train[count] = create_normal_label(x,R)\n",
    "                count+=1\n",
    "            selected.add(n)\n",
    "            \n",
    "    count = 0\n",
    "    while count<val_size:  # Get sample for val set\n",
    "        n = random.choice(V)\n",
    "        if n not in selected:\n",
    "            for i in range(n-256-128,n-256,16): # 8 windows\n",
    "                x = np.empty((514),'float32')\n",
    "                x[:512] = np.array([ecg[i:i+512]])\n",
    "                x[-2:] = [record,i+256]\n",
    "                x_val[count] = x\n",
    "                y_val[count] = create_normal_label(x,R)\n",
    "                count+=1\n",
    "            selected.add(n)\n",
    "    \n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling True Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''sampling true noise from each record'''\n",
    "\n",
    "def sampling_noise(path,R,record): \n",
    "    \n",
    "    R = sorted(list(R))\n",
    "    ecg = np.fromfile(path +'/ecg.dat', '>i2') \n",
    "    data_x,data_y = np.empty((150000,514),'float32'),np.empty((150000,8,2),'int') # initialize output\n",
    "    # 150000 is an abitrary large number. It is used cuz exact number of noise in the record is unknown\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for i, loc in enumerate(R[1:]):\n",
    "        dis=loc-R[i]\n",
    "        if dis>1064 and count<150000: #1064 considered +-20 of the R peak\n",
    "            for n in range(R[i]+257,loc-257,25):\n",
    "                x = np.empty((514),'float32')\n",
    "                x[:512] = np.array([ecg[n-256:n+256]])\n",
    "                x[-2:] = [record,n]\n",
    "                data_x[count] = x\n",
    "                data_y[count] = create_noise_label() \n",
    "                count+=1\n",
    "\n",
    "    if count ==0: # when no noise in the record\n",
    "        return [],[],0\n",
    "    \n",
    "    x_noise,y_noise = np.copy(data_x[:count]),np.copy(data_y[:count]) # make copy to avoid memory leak\n",
    "    del data_x\n",
    "    del data_y\n",
    "    \n",
    "    return x_noise,y_noise,count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Regular Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create sine/square/triangle waves as regular noise'''\n",
    "\n",
    "def get_sin(freq_low, freq_high, size=747):\n",
    "    \n",
    "    data_x, data_y = np.empty((size,514),'float32'),np.empty((size,8,2),'int') # initialize output\n",
    "    \n",
    "    count = 0\n",
    "    time_axis = np.arange(512)\n",
    "    for freq in range(freq_low, freq_high+1): # get sine with multiple frequency and phase\n",
    "        B = 2*np.pi*freq/256\n",
    "        for phi in range(int(256/freq)):\n",
    "            print('Get sine '+str(count)+'/ '+str(size), end = '\\r')\n",
    "            sine = np.sin(B*time_axis-B*phi)\n",
    "            data_x[count] = append(sine,[0,0])\n",
    "            data_y[count] = create_noise_label()\n",
    "            count+=1 \n",
    "    return data_x,data_y\n",
    "    \n",
    "    \n",
    "def get_square(freq_low, freq_high, size=747):\n",
    "    data_x, data_y = np.empty((size,514),'float32'),np.empty((size,8,2),'int') # initialize output\n",
    "    count = 0\n",
    "    \n",
    "    for freq in range(freq_low, freq_high+1):\n",
    "        square = np.zeros(1024,'float32') # generate square wave wiht length 1024, but will only crop 512 segment from it\n",
    "        length,pos,i = int(256/(2*freq)),1,0\n",
    "        while i< 4*2*freq:\n",
    "            square[i*length:(i+1)*length] = np.ones(length,'int')*pos\n",
    "            pos *= -1\n",
    "            i+=1 \n",
    "        for phi in range(int(256/freq)): # sliding window to crop the length 512 from square wave according to phase\n",
    "            print('Get square '+str(count)+'/ '+str(size), end = '\\r')\n",
    "            data_x[count]=np.append(square[phi:phi+512],[0,0])\n",
    "            data_y[count] = create_noise_label()\n",
    "            count+=1\n",
    "    return data_x, data_y\n",
    "    \n",
    "    \n",
    "def get_triangle(freq_low, freq_high,size=747):\n",
    "    data_x, data_y = np.empty((size,514),'float32'),np.empty((size,8,2),'int') # initialize output\n",
    "    count = 0\n",
    "    \n",
    "    for freq in range(freq_low, freq_high+1):\n",
    "        tran = np.zeros(1024,'float32') # generate triangle wave wiht length 1024, but will only crop 512 segment from it\n",
    "        slope, part, period = 1/(256/(4*freq)), 256/(4*freq), 256//freq\n",
    "        for i in range(256//freq): # draw triangle wave with length 256\n",
    "            m = 256/(4*freq)\n",
    "            if (i//(256/(4*freq)))%4==0:\n",
    "                tran[i] = slope*i\n",
    "            elif (i//(256/(4*freq)))%4==3:\n",
    "                tran[i] = slope*i+(-1-slope*(3*part))\n",
    "            else:\n",
    "                tran[i] = -slope*i+slope*(part*2)\n",
    "        for i in range(1,4*freq): # copy length 256 for multi-times to make full 1024 length wave\n",
    "            tran[i*period:(i+1)*period] = tran[:period]\n",
    "\n",
    "        for phi in range(int(256/freq)): # sliding window to crop the length 512 from square wave according to phase\n",
    "            data_x[count]=np.append(tran[phi:phi+512],[0,0])\n",
    "            data_y[count] = create_noise_label()\n",
    "            count+=1\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation and TFRecord Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Obtain noise segments from em and ma noise record'''\n",
    "\n",
    "def noise_segment(coefficient, em_path = 'Record/em.dat', ma_path = 'Record/ma.dat'):\n",
    "    em = np.fromfile(em_path,'>i2') # upload noise record \n",
    "    ma = np.fromfile(ma_path,'>i2')\n",
    "    \n",
    "    noise_sample = np.empty((20,512),'float32') #[em1_1,em1_2,ma1_1,ma1_2...,em5_1,em5_2,ma5_1,ma5_2]\n",
    "    orig_noise = np.empty((10,512),'float32') #[em1,ma1,em2,ma2,..., em5,ma5]\n",
    "    \n",
    "    # randomly obtained 5 noise samples from em and ma seperatively and stored in orig_noise\n",
    "    start,end,step,index = len(em)//5//2,len(em),len(em)//5,0 \n",
    "    for n in range(start,end,step):\n",
    "        sample_em = em[n-256:n+256]\n",
    "        orig_noise[index] = sample_em\n",
    "        sample_ma = ma[n-256:n+256]\n",
    "        orig_noise[index+1] = sample_ma\n",
    "        index+=2\n",
    "        \n",
    "    # for each noise sample obtained, applied coefficient to it and stored in noise_sample\n",
    "    index = 0\n",
    "    for i,noise in enumerate(orig_noise):\n",
    "        for e in coefficient[i]:\n",
    "            noise_sample[index] = noise*e\n",
    "            index+=1\n",
    "    \n",
    "    return noise_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Do stationary wavelet decomposition;\n",
    "   Save samples to tfrecord file'''\n",
    "\n",
    "def putSample(writer, size, data_x, data_y):\n",
    "    for i in range(size):\n",
    "        y = data_y[i].reshape(16)\n",
    "        \n",
    "        sample = decomp(data_x[i][:-2],'db2',(512,8)).reshape(4096) # stationary wavelet decomposition using db wavelet\n",
    "        x = np.empty((4098),'float32')\n",
    "        x[:4096] = sample\n",
    "        x[-2:] = data_x[i][-2:]\n",
    "\n",
    "        # create example and write to tfrecord\n",
    "        feature = {\n",
    "            'ecg': tf.train.Feature(float_list=tf.train.FloatList(value=x)),\n",
    "            'label': tf.train.Feature(float_list=tf.train.FloatList(value=y)),\n",
    "        }\n",
    "        example = tf.train.Example(features = tf.train.Features(feature = feature))\n",
    "        writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Add em/ma noise to each sample;\n",
    "   Do stationary wavelet decomposition on each sample;\n",
    "   Save samples to tfrecord file'''\n",
    "\n",
    "def putSample_AddingNoise(writer, size, data_x, data_y, noise_sample):\n",
    "    for i in range(size):\n",
    "        y = data_y[i].reshape(16)\n",
    "        for noise in noise_sample:\n",
    "            sample = decomp(data_x[i][:-2]+noise,'db2',(512,8)).reshape(4096) #stationary wavelet decomposition using db wavelet\n",
    "            x = np.empty((4098),'float32')\n",
    "            x[:4096] = sample\n",
    "            x[-2:] = data_x[i][-2:]\n",
    "\n",
    "            # # create example and write to tfrecord\n",
    "            feature = {\n",
    "                'ecg': tf.train.Feature(float_list=tf.train.FloatList(value=x)),\n",
    "                'label': tf.train.Feature(float_list=tf.train.FloatList(value=y)),\n",
    "            }\n",
    "            example = tf.train.Example(features = tf.train.Features(feature = feature))\n",
    "            writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle x and y; split to val set/train set\n",
    "def shuffle_and_split(data_x,data_y,seed = 10,size = 0.03):\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(data_x)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(data_y)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(data_x,data_y, test_size=0.03)\n",
    "    return x_train, x_val, y_train, y_val\n",
    "\n",
    "\n",
    "# get the name of each record folder\n",
    "def findSubdir(path):\n",
    "    subdir = [x for x in os.walk(path)]\n",
    "    subdir[0][1].remove('lorenz_plots')\n",
    "    return subdir[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "em1 = [0.2,0.5] # coefficient for each em/ma noise segment\n",
    "em2 = [0.1,0.15]\n",
    "em3 = [0.2,0.5]\n",
    "em4 = [0.1,0.3]\n",
    "em5 = [0.1,0.2]\n",
    "\n",
    "ma1 = [0.3,0.7]\n",
    "ma2 = [0.5,1.3]\n",
    "ma3 = [0.5,1.4]\n",
    "ma4 = [1,4]\n",
    "ma5 = [0.5,1.3]\n",
    "coefficient = np.array([em1,ma1,em2,ma2,em3,ma3,em4,ma4,em5,ma5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20001 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20002 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20003 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20004 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20005 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20006 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20007 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20008 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20009 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20010 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20011 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20012 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20013 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20014 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20015 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20016 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20017 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20018 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20019 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20020 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20021 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20022 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20023 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20024 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20025 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20026 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20027 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20028 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20029 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20030 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20031 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20032 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20033 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20034 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20035 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20036 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20037 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20038 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20039 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20040 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20041 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20042 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20043 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20044 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20045 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20046 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20047 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20048 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20049 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20050 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20051 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20052 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20053 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20054 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20055 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20056 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20057 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20058 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20059 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20060 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20061 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20062 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "20063 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20064 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20065 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "20066 normal sampling finished\n",
      "      normal store finished       \n",
      "      premature beat store finished       \n",
      "      noise sampling finished\n",
      "     noise store finished       \n",
      "sine, square, traingle finished\n"
     ]
    }
   ],
   "source": [
    "total_val = 0 # validate set/ train set/ noise counter\n",
    "total_train = 0\n",
    "total_noise = {}\n",
    "\n",
    "lydhdb = findSubdir('db/lydhdb') # get all record folder name\n",
    "lydhdb = sorted(lydhdb)\n",
    "\n",
    "with tf.io.TFRecordWriter('/tmpdata/val.tfrecords') as val_writer:\n",
    "    for i in range(0,9):\n",
    "        with tf.io.TFRecordWriter('/tmpdata/train_'+str(i+1)+'.tfrecords') as train_writer:\n",
    "            records = lydhdb[i*8:(i+1)*8] if i!=8 else lydhdb[i*8:]\n",
    "            for record in records:\n",
    "                path = 'db/lydhdb/'+record\n",
    "\n",
    "                R,A,V = annProcess(path) \n",
    "\n",
    "                noise_sample = noise_segment(coefficient)\n",
    "\n",
    "                x_train, x_val, y_train, y_val = sampling_normal(path,R,record,576,560) # sampling \n",
    "                print(record + ' normal sampling finished')\n",
    "                \n",
    "                putSample_AddingNoise(train_writer, len(x_train), x_train,y_train,noise_sample) # store train sample to TFrecord\n",
    "                putSample(train_writer,len(x_train),x_train,y_train)\n",
    "                putSample(val_writer, len(x_val), x_val,y_val)\n",
    "                total_val+=len(x_val)\n",
    "                total_train+=len(x_train)\n",
    "                print('      normal store finished       ')  \n",
    "                \n",
    "                if len(A)>=14: # sampling period with A\n",
    "                    x_train, x_val, y_train, y_val = sampling_A(path,R,A,record,int(len(A)*0.075)*16,int(len(A)*0.148)*8)\n",
    "                    putSample_AddingNoise(train_writer,len(x_train),x_train,y_train,noise_sample) \n",
    "                    putSample(train_writer,len(x_train),x_train,y_train)\n",
    "                    putSample(val_writer, len(x_val), x_val,y_val)\n",
    "                    total_val+=len(x_val)\n",
    "                    total_train+=len(x_train)\n",
    "                \n",
    "                if len(V)>=50: # sampling period with V\n",
    "                    x_train, x_val, y_train, y_val = sampling_V(path,R,V,record,int(len(V)*0.02)*32,int(len(V)*0.078)*8)\n",
    "                    putSample_AddingNoise(train_writer,len(x_train),x_train,y_train,noise_sample)\n",
    "                    putSample(train_writer,len(x_train),x_train,y_train)\n",
    "                    putSample(val_writer, len(x_val), x_val,y_val)\n",
    "                    total_val+=len(x_val)\n",
    "                    total_train+=len(x_train)\n",
    "                print('      premature beat store finished       ')\n",
    "                \n",
    "                x_noise, y_noise,count_noise = sampling_noise(path,R,record) # sampling true noise sample\n",
    "                total_noise[record] = count_noise\n",
    "                print('      noise sampling finished')\n",
    "                \n",
    "                if len(x_noise)!=0:\n",
    "                    x_train, x_val, y_train, y_val = shuffle_and_split(x_noise,y_noise,seed = 10,size = 0.03)\n",
    "                    \n",
    "                    putSample(train_writer, len(x_train), x_train,y_train) # store train sample to TFrecord\n",
    "                    putSample(val_writer, len(x_val), x_val,y_val)\n",
    "                    total_val+=len(x_val)\n",
    "                    total_train+=len(x_train)\n",
    "                    print('     noise store finished       ')  \n",
    "\n",
    "            if i==8: # get regular noise\n",
    "                x_sine,y_sine = get_sin(1,10)\n",
    "                x_square, y_square = get_square(1,10)\n",
    "                x_tran, y_tran = get_triangle(1,10)\n",
    "                putSample(train_writer, 747, x_sine,y_sine)\n",
    "                putSample(train_writer, 747, x_square, y_square)\n",
    "                putSample(train_writer, 747, x_tran, y_tran)\n",
    "                total_train+=len(x_sine)\n",
    "                total_train+=len(x_square)\n",
    "                total_train+=len(x_tran)\n",
    "                print('sine, square, traingle finished') \n",
    "\n",
    "        train_writer.close()\n",
    "val_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89021, 382048)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_val,total_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307684"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = 0 \n",
    "for x in total_noise:       # total true noise\n",
    "    noise+=total_noise[x]\n",
    "noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
